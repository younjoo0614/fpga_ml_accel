{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSD-2021 Project (CIFAR-10)\n",
    "---\n",
    "## Simple python inference implementation\n",
    "- This is a pytorch implementation of CIFAR-10 inference to help you understand how ML inference works\n",
    "\n",
    "## Usage\n",
    "- Run all the cells to see how ML inference works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.layers_cifar10 import *\n",
    "from utils.bit_operation import *\n",
    "from utils.setup_cifar10 import *\n",
    "from utils.scale_uart import *\n",
    "import time\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download the CIFAR-10 dataset         \n",
    "\n",
    "https://www.cs.toronto.edu/~kriz/cifar.html\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Unzip the gz file into ubyte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unzip_cifar10(\"./dataset_cifar10/cifar-10-python.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the CIFAR-10 dataset\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN SET\n",
    "X_train, y_train = load_CIFAR10_batch(\"data_batch_1\")\n",
    "# TEST SET\n",
    "X_test, y_test = load_CIFAR10_test()\n",
    "# TEST ORIGIN for generating images\n",
    "X_test_origin, _ = load_CIFAR10_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mask the number of dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test[range(100)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show example CIFAR-10 Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = [\"Airplane\", \"Automobile\", \"Bird\", \"Cat\", \"Deer\", \"Dog\", \"Frog\", \\\n",
    "              \"Horse\", \"Ship\", \"Truck\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    key = np.random.randint(10000)\n",
    "    gen_image(X_test_origin[key]).show()\n",
    "    print(\"Label: %d (%s)\" %(y_test[key], label_list[y_test[key]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess the dataset (normalize)  \n",
    "\n",
    "It will be **not included** in out PROJECT IMPLEMENATION.\n",
    "\n",
    "---\n",
    "\n",
    "CIFAR-10 Loader have already done the normalization (So, X_train /= 255 will be skipped.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mean = [np.mean(X_train[:, 0, :, :]), np.mean(X_train[:, 1, :, :]), np.mean(X_train[:, 2, :, :])]\n",
    "std = [np.std(X_train[:, 0, :, :]), np.std(X_train[:, 2, :, :]), np.std(X_train[:, 2, :, :])]\n",
    "print(\"mean:\\t%.4f, %.4f, %.4f\" %(mean[0], mean[1], mean[2]))\n",
    "print(\"std:\\t%.4f, %.4f, %.4f\" %(std[0], std[1], std[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Pre-processing\n",
    "m = [0.4935, 0.4834, 0.4472]\n",
    "std = [0.2476, 0.2626, 0.2626]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only pre-process the test dataset\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 3, 32, 32))\n",
    "for i in range(3):\n",
    "    X_test[:,i,:,:] = (X_test[:,i,:,:]-m[i])/std[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train  \n",
    "---\n",
    "It is already done by TAs.  \n",
    "So just load the pre-trained network parameters!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simulation data for our 8-bit MAC unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre quantized dataset\n",
    "X_test_ = np.load(\"./data/cifar10_dataset_quan/images_100.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load network parameter\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load network param\n",
    "conv1_w = np.load(\"./data/cifar10_network_param/cifar10_conv1_weight.npy\")\n",
    "conv1_b = np.load(\"./data/cifar10_network_param/cifar10_conv1_bias.npy\")\n",
    "conv2_w = np.load(\"./data/cifar10_network_param/cifar10_conv2_weight.npy\")\n",
    "conv2_b = np.load(\"./data/cifar10_network_param/cifar10_conv2_bias.npy\")\n",
    "conv3_w = np.load(\"./data/cifar10_network_param/cifar10_conv3_weight.npy\")\n",
    "conv3_b = np.load(\"./data/cifar10_network_param/cifar10_conv3_bias.npy\")\n",
    "conv4_w = np.load(\"./data/cifar10_network_param/cifar10_conv4_weight.npy\")\n",
    "conv4_b = np.load(\"./data/cifar10_network_param/cifar10_conv4_bias.npy\")\n",
    "conv5_w = np.load(\"./data/cifar10_network_param/cifar10_conv5_weight.npy\")\n",
    "conv5_b = np.load(\"./data/cifar10_network_param/cifar10_conv5_bias.npy\")\n",
    "conv6_w = np.load(\"./data/cifar10_network_param/cifar10_conv6_weight.npy\")\n",
    "conv6_b = np.load(\"./data/cifar10_network_param/cifar10_conv6_bias.npy\")\n",
    "fc1_w =   np.load(\"./data/cifar10_network_param/cifar10_fc1_weight.npy\")\n",
    "fc1_b =   np.load(\"./data/cifar10_network_param/cifar10_fc1_bias.npy\")\n",
    "fc2_w =   np.load(\"./data/cifar10_network_param/cifar10_fc2_weight.npy\")\n",
    "fc2_b =   np.load(\"./data/cifar10_network_param/cifar10_fc2_bias.npy\")\n",
    "fc3_w =   np.load(\"./data/cifar10_network_param/cifar10_fc3_weight.npy\")\n",
    "fc3_b =   np.load(\"./data/cifar10_network_param/cifar10_fc3_bias.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load quantized network param\n",
    "conv1_w_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv1_weight_quan.npy\")\n",
    "conv1_b_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv1_bias_quan.npy\")\n",
    "conv2_w_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv2_weight_quan.npy\")\n",
    "conv2_b_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv2_bias_quan.npy\")\n",
    "conv3_w_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv3_weight_quan.npy\")\n",
    "conv3_b_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv3_bias_quan.npy\")\n",
    "conv4_w_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv4_weight_quan.npy\")\n",
    "conv4_b_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv4_bias_quan.npy\")\n",
    "conv5_w_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv5_weight_quan.npy\")\n",
    "conv5_b_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv5_bias_quan.npy\")\n",
    "conv6_w_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv6_weight_quan.npy\")\n",
    "conv6_b_ = np.load(\"./data/cifar10_network_quan_param/cifar10_conv6_bias_quan.npy\")\n",
    "fc1_w_ =   np.load(\"./data/cifar10_network_quan_param/cifar10_fc1_weight_quan.npy\")\n",
    "fc1_b_ =   np.load(\"./data/cifar10_network_quan_param/cifar10_fc1_bias_quan.npy\")\n",
    "fc2_w_ =   np.load(\"./data/cifar10_network_quan_param/cifar10_fc2_weight_quan.npy\")\n",
    "fc2_b_ =   np.load(\"./data/cifar10_network_quan_param/cifar10_fc2_bias_quan.npy\")\n",
    "fc3_w_ =   np.load(\"./data/cifar10_network_quan_param/cifar10_fc3_weight_quan.npy\")\n",
    "fc3_b_ =   np.load(\"./data/cifar10_network_quan_param/cifar10_fc3_bias_quan.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for accuracy  \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_param = {'stride': 1, 'pad': 1}\n",
    "pool_param = {'pool_height': 2, 'pool_width': 2, 'stride': 2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(data):\n",
    "    # CONV1 with MAXPOOL\n",
    "    conv1_out = conv(data, conv1_w, conv1_b, conv_param)\n",
    "    relu1_out = relu(conv1_out)\n",
    "    pool1_out = maxpool(relu1_out, pool_param)\n",
    "    \n",
    "    # CONV2 with MAXPOOL\n",
    "    conv2_out = conv(pool1_out, conv2_w, conv2_b, conv_param)\n",
    "    relu2_out = relu(conv2_out)\n",
    "    pool2_out = maxpool(relu2_out, pool_param)\n",
    "    \n",
    "    # CONV3 with MAXPOOL\n",
    "    conv3_out = conv(pool2_out, conv3_w, conv3_b, conv_param)\n",
    "    relu3_out = relu(conv3_out)\n",
    "    \n",
    "    # CONV4 with MAXPOOL\n",
    "    conv4_out = conv(relu3_out, conv4_w, conv4_b, conv_param)\n",
    "    relu4_out = relu(conv4_out)\n",
    "    pool4_out = maxpool(relu4_out, pool_param)\n",
    "    \n",
    "    # CONV5 with MAXPOOL\n",
    "    conv5_out = conv(pool4_out, conv5_w, conv5_b, conv_param)\n",
    "    relu5_out = relu(conv5_out)\n",
    "    \n",
    "    # CONV6 with MAXPOOL\n",
    "    conv6_out = conv(relu5_out, conv6_w, conv6_b, conv_param)\n",
    "    relu6_out = relu(conv6_out)\n",
    "    pool6_out = maxpool(relu6_out, pool_param)\n",
    "    \n",
    "    # Flatten for FC's input\n",
    "    flat = np.reshape(pool6_out, (1024,))\n",
    "    \n",
    "    # Fully-Connected 1\n",
    "    fc1_out = fully_connected(flat, fc1_w, fc1_b)\n",
    "    relu7_out = relu(fc1_out)\n",
    "    \n",
    "    # Fully-Connected 2\n",
    "    fc2_out = fully_connected(relu7_out, fc2_w, fc2_b)\n",
    "    relu8_out = relu(fc2_out)\n",
    "    \n",
    "    # Fully-Connected 1\n",
    "    fc3_out = fully_connected(relu8_out, fc3_w, fc3_b)\n",
    "    # !!! EXCLUSION OF RELU ON LAST LAYER !!!\n",
    "    return fc3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference_quan(data):\n",
    "    # CONV1 with MAXPOOL\n",
    "    conv1_out = conv(data, conv1_w_, conv1_b_, conv_param)\n",
    "    relu1_out = relu(conv1_out)\n",
    "    relu1_out = to_8bit_fixed(relu1_out)\n",
    "    pool1_out = maxpool(relu1_out, pool_param)\n",
    "    # EACH OUTPUT MUST BE TRANSLATED INTO 8-BIT FORM\n",
    "    pool1_out_ = to_8bit_fixed(pool1_out)\n",
    "    \n",
    "    # CONV2 with MAXPOOL\n",
    "    conv2_out = conv(pool1_out_, conv2_w_, conv2_b_, conv_param)\n",
    "    relu2_out = relu(conv2_out)\n",
    "    relu2_out = to_8bit_fixed(relu2_out)\n",
    "    pool2_out = maxpool(relu2_out, pool_param)\n",
    "    # EACH OUTPUT MUST BE TRANSLATED INTO 8-BIT FORM\n",
    "    pool2_out_ = to_8bit_fixed(pool2_out)\n",
    "    \n",
    "    # CONV3 with MAXPOOL\n",
    "    conv3_out = conv(pool2_out_, conv3_w_, conv3_b_, conv_param)\n",
    "    relu3_out = relu(conv3_out)\n",
    "    # EACH OUTPUT MUST BE TRANSLATED INTO 8-BIT FORM\n",
    "    relu3_out_ = to_8bit_fixed(relu3_out)\n",
    "    \n",
    "    # CONV4 with MAXPOOL\n",
    "    conv4_out = conv(relu3_out_, conv4_w_, conv4_b_, conv_param)\n",
    "    relu4_out = relu(conv4_out)\n",
    "    relu4_out = to_8bit_fixed(relu4_out)\n",
    "    pool4_out = maxpool(relu4_out, pool_param)\n",
    "    # EACH OUTPUT MUST BE TRANSLATED INTO 8-BIT FORM\n",
    "    pool4_out_ = to_8bit_fixed(pool4_out)\n",
    "    \n",
    "    # CONV5 with MAXPOOL\n",
    "    conv5_out = conv(pool4_out_, conv5_w_, conv5_b_, conv_param)\n",
    "    relu5_out = relu(conv5_out)\n",
    "    relu5_out = to_8bit_fixed(relu5_out)\n",
    "    # EACH OUTPUT MUST BE TRANSLATED INTO 8-BIT FORM\n",
    "    relu5_out_ = to_8bit_fixed(relu5_out)\n",
    "    \n",
    "    # CONV6 with MAXPOOL\n",
    "    conv6_out = conv(relu5_out_, conv6_w_, conv6_b_, conv_param)\n",
    "    relu6_out = relu(conv6_out)\n",
    "    relu6_out = to_8bit_fixed(relu6_out)\n",
    "    pool6_out = maxpool(relu6_out, pool_param)\n",
    "    # EACH OUTPUT MUST BE TRANSLATED INTO 8-BIT FORM\n",
    "    pool6_out_ = to_8bit_fixed(pool6_out)\n",
    "    \n",
    "    # Flatten for FC's input\n",
    "    flat = np.reshape(pool6_out_, (1024,))\n",
    "    \n",
    "    # Fully-Connected 1\n",
    "    fc1_out = fully_connected(flat, fc1_w_, fc1_b_)\n",
    "    relu7_out = relu(fc1_out)\n",
    "    # EACH OUTPUT MUST BE TRANSLATED INTO 8-BIT FORM\n",
    "    fc1_out_ = to_8bit_fixed(relu7_out)\n",
    "    \n",
    "    # Fully-Connected 2\n",
    "    fc2_out = fully_connected(fc1_out_, fc2_w_, fc2_b_)\n",
    "    relu8_out = relu(fc2_out)\n",
    "    # EACH OUTPUT MUST BE TRANSLATED INTO 8-BIT FORM\n",
    "    fc2_out_ = to_8bit_fixed(relu8_out)\n",
    "    \n",
    "    # Fully-Connected 1\n",
    "    fc3_out = fully_connected(fc2_out_, fc3_w_, fc3_b_)\n",
    "    # !!! EXCLUSION OF RELU ON LAST LAYER !!!\n",
    "    # CAN SKIP THE QUNATIZATION STEP B.C WE ALLOW 16-BIT OUTCOME ON LAST\n",
    "    return fc3_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(data):\n",
    "    num_img = data.shape[0]\n",
    "    pred_label = list()\n",
    "    scores = list()\n",
    "    for idx in range(num_img):\n",
    "        score = inference(data[idx].reshape((1, 3, 32, 32)))\n",
    "        scores.append(score)\n",
    "        print(\"Progress: {:05.2f}%\".format(100*idx/(num_img-1)), end=\"\\r\", flush=True)\n",
    "        pred_label.append(np.argmax(score, axis=0))\n",
    "    return scores, pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_quan(data):\n",
    "    num_img = data.shape[0]\n",
    "    pred_label = list()\n",
    "    scores = list()\n",
    "    for idx in range(num_img):\n",
    "        score = inference_quan(data[idx].reshape((1, 3, 32, 32)))\n",
    "        scores.append(score)\n",
    "        print(\"Progress: {:05.2f}%\".format(100*(idx+1)/100), end=\"\\r\", flush=True)\n",
    "        pred_label.append(np.argmax(score, axis=0))\n",
    "    return scores, pred_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do inference and Check the accuracy\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CHECK MASKED DATA (range 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 images quantized predict\n",
    "start = time.time()\n",
    "scores_mask_quan, pred_mask_quan = check_accuracy_quan(X_test_)\n",
    "print(\"Total time: {:.2f} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i in range(100):\n",
    "    if pred_mask_quan[i] == y_test[i]:\n",
    "        acc += 1\n",
    "    if i % 10 == 0:\n",
    "        gen_image(X_test_origin[i]).show()\n",
    "        print(\"Label: %d (%s)\" %(y_test[i], label_list[y_test[i]]))\n",
    "        print(\"Predict: %d (%s)\" %(pred_mask_quan[i], label_list[pred_mask_quan[i]]))\n",
    "print(\"\\t100 images accuracy: {:.2f}%\".format(acc/100 * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 100 images predict\n",
    "start = time.time()\n",
    "scores_mask, pred_mask = check_accuracy(X_test)\n",
    "print(\"Total time: {:.2f} sec\".format(time.time() - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = 0\n",
    "for i in range(100):\n",
    "    if pred_mask[i] == y_test[i]:\n",
    "        acc += 1\n",
    "    if i % 10 == 0:\n",
    "        gen_image(X_test_origin[i]).show()\n",
    "        print(\"Label: %d (%s)\" %(y_test[i], label_list[y_test[i]]))\n",
    "        print(\"Predict: %d (%s)\" %(pred_mask[i], label_list[pred_mask[i]]))\n",
    "print(\"\\t100 images accuracy: {:.2f}%\".format(acc/100 * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to debug and Check the output?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---  \n",
    "In software_inference, you can see the result data by below code.  \n",
    "You can revise this code for checking your own.  \n",
    "**ALL YOUR DATA IN THIS FORMAT WILL BE PRINTED WITH BIG ENDIAN**  \n",
    "**ON DRAM, DATA WERE STORED IN LITTLE ENDIAN ORDER**  \n",
    "So, you should read in reversed order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "example:\n",
    "\n",
    "below result:\n",
    "[1, 11, 2, 22]\n",
    "\n",
    "Then on DRAM:\n",
    "[22, 2, 11, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv1_out = conv(X_test_[0].reshape(1, 3, 32, 32), conv1_w_, conv1_b_, conv_param)\n",
    "relu1_out = relu(conv1_out)\n",
    "relu1_out_quan = to_8bit_fixed(relu1_out)\n",
    "relu1_out_bin = to_8bit_fixed_binary(relu1_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(relu1_out_quan.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_convrelu1 = relu1_out_quan.flatten()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print in 4 Bytes\n",
    "for i in range(int(1 * 3 * 32 * 32 / 4)):\n",
    "    temp = flat_convrelu1[i*4:i*4+4]\n",
    "    print(i, \"\\t\", temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_convrelu_bin1 = relu1_out_bin.flatten()               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print in 4 Bytes\n",
    "for i in range(int(1 * 3 * 32 * 32 / 4)):\n",
    "    temp = flat_convrelu_bin1[i*4:i*4+4]\n",
    "    print(i, \"\\t\", temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11 in binary means that \n",
    "# 00001011 = 1 * (0.125 + 0.03125 + 0.015625) = 0.171875"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
